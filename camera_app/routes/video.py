from flask import Blueprint, Response
import cv2
from ultralytics import YOLO
import threading
import torch
import time
import requests
from datetime import datetime, timezone

video_bp = Blueprint('video', __name__)

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"üñ•Ô∏è  –ò—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
if device == 'cuda':
    print(f"üìä GPU: {torch.cuda.get_device_name(0)}")
    print(f"üìà CUDA –≤–µ—Ä—Å–∏—è: {torch.version.cuda}")

model = YOLO('yolov8n.pt').to(device)

cap1 = None
cap2 = None

frame_lock1 = threading.Lock()
frame_lock2 = threading.Lock()
current_frame1 = None
current_frame2 = None

MAX_FPS = 15
FRAME_TIME = 1.0 / MAX_FPS

# –ê–¥—Ä–µ—Å —Å–µ—Ä–≤–µ—Ä–∞ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
SERVER_URL = 'http://127.0.0.1:5001/api/coordinates/receive'

# –ü–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–ø—Ä–∞–≤–∫–∏ (—Ä–∞–∑ –≤ —Å–µ–∫—É–Ω–¥—É)
last_send_time = {}


def init_camera(camera_id, camera_num):
    global cap1, cap2

    try:
        if camera_num == 1:
            if cap1:
                cap1.release()
            cap1 = cv2.VideoCapture(camera_id, cv2.CAP_DSHOW)
            cap1.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            cap1.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            last_send_time[1] = 0
            print(f"‚úì –ö–∞–º–µ—Ä–∞ 1 –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞: ID {camera_id}")
        else:
            if cap2:
                cap2.release()
            cap2 = cv2.VideoCapture(camera_id, cv2.CAP_DSHOW)
            cap2.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            cap2.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            last_send_time[2] = 0
            print(f"‚úì –ö–∞–º–µ—Ä–∞ 2 –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞: ID {camera_id}")
    except Exception as e:
        print(f"‚úó –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–∞–º–µ—Ä—ã {camera_num}: {e}")


def detect_persons(frame):
    """–î–µ—Ç–µ–∫—Ü–∏—è –ª—é–¥–µ–π –∏ –≤–æ–∑–≤—Ä–∞—Ç –∏—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç"""
    persons = []

    try:
        results = model(frame, conf=0.5, verbose=False, device=device)

        for result in results:
            for box in result.boxes:
                if int(box.cls) == 0:  # person
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    conf = float(box.conf[0])

                    # –¶–µ–Ω—Ç—Ä –æ–±—ä–µ–∫—Ç–∞
                    center_x = (x1 + x2) // 2
                    center_y = (y1 + y2) // 2

                    persons.append({
                        'x': center_x,
                        'y': center_y,
                        'confidence': conf
                    })
    except Exception as e:
        print(f"‚úó –û—à–∏–±–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏: {e}")

    return persons


def send_coordinates(persons, camera_num):
    current_time = time.time()

    if camera_num in last_send_time:
        if current_time - last_send_time[camera_num] < 1: # —á–∞—Å—Ç–æ—Ç–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–∏–≥–Ω–∞–ª–∞
            return

    last_send_time[camera_num] = current_time

    # –ù–û–í–û–ï: –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–∞–∂–µ –µ—Å–ª–∏ –ª—é–¥–µ–π –Ω–µ—Ç
    utc_time = datetime.now(timezone.utc).isoformat()

    if persons:  # –ß–µ–ª–æ–≤–µ–∫(–∏) –Ω–∞–π–¥–µ–Ω—ã
        person = persons[0]
        data = {
            'camera_id': camera_num,
            'x': person['x'],
            'y': person['y'],
            'confidence': person['confidence'],
            'has_person': True,  # ‚Üê –ù–û–í–û–ï
            'timestamp': utc_time
        }
        print(f"‚úì –ö–∞–º–µ—Ä–∞ {camera_num}: –ù–∞–π–¥–µ–Ω —á–µ–ª–æ–≤–µ–∫ X={person['x']}, Y={person['y']}")
    else:  # –õ—é–¥–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
        data = {
            'camera_id': camera_num,
            'x': 320,  # –¶–µ–Ω—Ç—Ä
            'y': 240,  # –¶–µ–Ω—Ç—Ä
            'confidence': 0,
            'has_person': False,  # ‚Üê –ù–û–í–û–ï
            'timestamp': utc_time
        }
        print(f"‚ö†Ô∏è  –ö–∞–º–µ—Ä–∞ {camera_num}: –ß–µ–ª–æ–≤–µ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω")

    try:
        response = requests.post(SERVER_URL, json=data, timeout=2)
        if response.status_code != 200:
            print(f"‚úó –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {response.status_code}")
    except Exception as e:
        print(f"‚úó –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")


def process_frame(frame, camera_num):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞: –¥–µ—Ç–µ–∫—Ü–∏—è, —Ä–∏—Å–æ–≤–∞–Ω–∏–µ –±–æ–∫—Å–æ–≤"""
    frame_copy = frame.copy()

    persons = detect_persons(frame)

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –Ω–∞ —Å–µ—Ä–≤–µ—Ä
    send_coordinates(persons, camera_num)

    # –†–∏—Å—É–µ–º –±–æ–∫—Å—ã –≤–æ–∫—Ä—É–≥ –ª—é–¥–µ–π
    for person_data in persons:
        # –ü–æ–ª—É—á–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ –µ—â–µ –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å (–µ—Å–ª–∏ –Ω—É–∂–Ω—ã –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –±–æ–∫—Å–∞)
        results = model(frame, conf=0.5, verbose=False, device=device)
        for result in results:
            for box in result.boxes:
                if int(box.cls) == 0:
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    conf = float(box.conf[0])
                    cv2.rectangle(frame_copy, (x1, y1), (x2, y2), (0, 255, 0), 2)
                    cv2.putText(frame_copy, f'Person: {conf:.2f}', (x1, y1 - 10),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

    return frame_copy


def update_frames_camera1():
    global current_frame1
    last_time = time.time()

    while True:
        if cap1 is None:
            continue

        current_time = time.time()
        if current_time - last_time < FRAME_TIME:
            time.sleep(0.001)
            continue

        last_time = current_time

        ret, frame = cap1.read()
        if not ret:
            continue

        processed = process_frame(frame, 1)

        with frame_lock1:
            current_frame1 = processed


def update_frames_camera2():
    global current_frame2
    last_time = time.time()

    while True:
        if cap2 is None:
            continue

        current_time = time.time()
        if current_time - last_time < FRAME_TIME:
            time.sleep(0.001)
            continue

        last_time = current_time

        ret, frame = cap2.read()
        if not ret:
            continue

        processed = process_frame(frame, 2)

        with frame_lock2:
            current_frame2 = processed


@video_bp.route('/cameras', methods=['GET'])
def get_cameras():
    from flask import jsonify
    max_tested = 10
    available_cameras = []
    for i in range(max_tested):
        test_cap = cv2.VideoCapture(i, cv2.CAP_DSHOW)
        if test_cap is None or not test_cap.isOpened():
            test_cap.release()
            continue
        available_cameras.append({"id": i, "name": f"Camera {i}"})
        test_cap.release()
    return jsonify(available_cameras)


@video_bp.route('/select_camera/<int:camera_num>/<int:camera_id>', methods=['POST'])
def select_camera(camera_num, camera_id):
    from flask import jsonify
    init_camera(camera_id, camera_num)
    return jsonify({"camera_num": camera_num, "camera_id": camera_id})


@video_bp.route('/feed1')
def video_feed1():
    def generate():
        while True:
            with frame_lock1:
                if current_frame1 is None:
                    continue
                ret, buffer = cv2.imencode('.jpg', current_frame1)
                frame_bytes = buffer.tobytes()
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')

    return Response(generate(),
                    mimetype='multipart/x-mixed-replace; boundary=frame')


@video_bp.route('/feed2')
def video_feed2():
    def generate():
        while True:
            with frame_lock2:
                if current_frame2 is None:
                    continue
                ret, buffer = cv2.imencode('.jpg', current_frame2)
                frame_bytes = buffer.tobytes()
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')

    return Response(generate(),
                    mimetype='multipart/x-mixed-replace; boundary=frame')


init_camera(0, 1)
init_camera(0, 2)
print(f"‚è±Ô∏è  –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ FPS: {MAX_FPS} –∫–∞–¥—Ä–æ–≤/—Å–µ–∫")
print(f"üì° –°–µ—Ä–≤–µ—Ä –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç: {SERVER_URL}")
threading.Thread(target=update_frames_camera1, daemon=True).start()
threading.Thread(target=update_frames_camera2, daemon=True).start()
