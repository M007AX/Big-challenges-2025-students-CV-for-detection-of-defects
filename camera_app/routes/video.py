from flask import Blueprint, Response, jsonify
import cv2
from ultralytics import YOLO
import threading
import torch
import time
import requests
from datetime import datetime, timezone
import platform
import os

video_bp = Blueprint('video', __name__)

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"üñ•Ô∏è  –ò—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
if device == 'cuda':
    print(f"üìä GPU: {torch.cuda.get_device_name(0)}")
    print(f"üìà CUDA –≤–µ—Ä—Å–∏—è: {torch.version.cuda}")

# –í—ã–±–æ—Ä backend –∫–∞–º–µ—Ä—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –û–°
OS_NAME = platform.system()
if OS_NAME == 'Windows':
    CAMERA_BACKEND = cv2.CAP_DSHOW       # DirectShow –¥–ª—è Windows
elif OS_NAME == 'Linux':
    CAMERA_BACKEND = cv2.CAP_V4L2        # V4L2 –¥–ª—è Linux
else:
    CAMERA_BACKEND = cv2.CAP_ANY         # –ü—É—Å—Ç—å OpenCV —Å–∞–º –≤—ã–±–µ—Ä–µ—Ç backend

print(f"üé•  –û–°: {OS_NAME}, backend –∫–∞–º–µ—Ä—ã: {CAMERA_BACKEND}")

model = YOLO('/home/sirius/PycharmProjects/Big-challenges-2025-students-CV-for-detection-of-defects1/brak_ok_no_gaus.pt').to(device)

cap1 = None
cap2 = None

frame_lock1 = threading.Lock()
frame_lock2 = threading.Lock()
current_frame1 = None
current_frame2 = None

MAX_FPS = 60
FRAME_TIME = 1.0 / MAX_FPS

# –ê–¥—Ä–µ—Å —Å–µ—Ä–≤–µ—Ä–∞ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
SERVER_URL = 'http://127.0.0.1:5001/api/coordinates/receive'

# –ü–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–ø—Ä–∞–≤–∫–∏ (—Ä–∞–∑ –≤ —Å–µ–∫—É–Ω–¥—É)
last_send_time = {}


def init_camera(camera_id, camera_num):
    """
    –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞–º–µ—Ä—ã —Å –∑–∞–¥–∞–Ω–Ω—ã–º ID –∏ –Ω–æ–º–µ—Ä–æ–º (1 –∏–ª–∏ 2).
    –î–µ–ª–∞–µ—Ç –∫—Ä–æ—Å—Å–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω—ã–π –≤—ã–±–æ—Ä backend –∏ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç isOpened().
    """
    global cap1, cap2

    try:
        if camera_num == 1:
            # –ó–∞–∫—Ä—ã–≤–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –æ–±—ä–µ–∫—Ç, –µ—Å–ª–∏ –±—ã–ª
            if cap1 is not None:
                cap1.release()

            cap1 = cv2.VideoCapture(camera_id, CAMERA_BACKEND)

            if not cap1.isOpened():
                print(f"‚úó –ö–∞–º–µ—Ä–∞ 1 –Ω–µ –æ—Ç–∫—Ä—ã–ª–∞—Å—å: ID {camera_id}")
                cap1.release()
                cap1 = None
                return

            cap1.set(cv2.CAP_PROP_FRAME_WIDTH, 960)
            cap1.set(cv2.CAP_PROP_FRAME_HEIGHT, 540)
            last_send_time[1] = 0
            print(f"‚úì –ö–∞–º–µ—Ä–∞ 1 –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞: ID {camera_id}")

        else:
            if cap2 is not None:
                cap2.release()

            cap2 = cv2.VideoCapture(camera_id, CAMERA_BACKEND)

            if not cap2.isOpened():
                print(f"‚úó –ö–∞–º–µ—Ä–∞ 2 –Ω–µ –æ—Ç–∫—Ä—ã–ª–∞—Å—å: ID {camera_id}")
                cap2.release()
                cap2 = None
                return

            cap2.set(cv2.CAP_PROP_FRAME_WIDTH, 960)
            cap2.set(cv2.CAP_PROP_FRAME_HEIGHT, 540)
            last_send_time[2] = 0
            print(f"‚úì –ö–∞–º–µ—Ä–∞ 2 –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞: ID {camera_id}")

    except Exception as e:
        print(f"‚úó –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–∞–º–µ—Ä—ã {camera_num}: {e}")


def detect_persons(frame):
    """–î–µ—Ç–µ–∫—Ü–∏—è –ª—é–¥–µ–π –∏ –≤–æ–∑–≤—Ä–∞—Ç –∏—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç"""
    persons = []

    try:
        results = model(frame, conf=0.5, verbose=False, device=device)
        class_thresholds = {
            0: 0.9,
            1: 0.75
        }

        for result in results:
            for box in result.boxes:
                if int(box.cls) == 0 and float(box.conf[0]) >= 0.9 or (int(box.cls) == 1):  # person
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    conf = float(box.conf[0])

                    # –¶–µ–Ω—Ç—Ä –æ–±—ä–µ–∫—Ç–∞
                    center_x = (x1 + x2) // 2
                    center_y = (y1 + y2) // 2

                    persons.append({
                        'x': center_x,
                        'y': center_y,
                        'confidence': int(box.cls)
                    })
    except Exception as e:
        print(f"‚úó –û—à–∏–±–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏: {e}")

    return persons


def send_coordinates(persons, camera_num):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –Ω–∞ —Å–µ—Ä–≤–µ—Ä —Ä–∞–∑ –≤ N —Å–µ–∫—É–Ω–¥"""
    current_time = time.time()

    if camera_num in last_send_time:
        # –†–∞–∑ –≤ 10 —Å–µ–∫—É–Ω–¥, –∫–∞–∫ —É —Ç–µ–±—è –≤ –∏—Å—Ö–æ–¥–Ω–∏–∫–µ
        if current_time - last_send_time[camera_num] < 0.02:
            return

    last_send_time[camera_num] = current_time

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–∞–∂–µ –µ—Å–ª–∏ –ª—é–¥–µ–π –Ω–µ—Ç
    utc_time = datetime.now(timezone.utc).isoformat()

    if persons and persons[0]['confidence'] == 0:  # –ß–µ–ª–æ–≤–µ–∫(–∏) –Ω–∞–π–¥–µ–Ω—ã
        person = persons[0]
        data = {
            'camera_id': camera_num,
            'x': person['x'],
            'y': person['y'],
            'confidence': person['confidence'],
            'has_person': True,
            'timestamp': utc_time
        }
        print(f"‚úì –ö–∞–º–µ—Ä–∞ {camera_num}: –ù–∞–π–¥–µ–Ω cup X={person['x']}, Y={person['y']}")
    else:  # –õ—é–¥–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
        data = {
            'camera_id': camera_num,
            'x': 320,   # –¶–µ–Ω—Ç—Ä
            'y': 240,   # –¶–µ–Ω—Ç—Ä
            'confidence': 0,
            'has_person': False,
            'timestamp': utc_time
        }
        print(f"‚ö†Ô∏è  –ö–∞–º–µ—Ä–∞ {camera_num}: cup –Ω–µ –Ω–∞–π–¥–µ–Ω")

    try:
        if persons and 520 > persons[0]['x'] > 400:
            response = requests.post(SERVER_URL, json=data, timeout=2)
            if response.status_code != 200:
                print(f"‚úó –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {response.status_code}")
    except Exception as e:
        print(f"‚úó –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")


def process_frame(frame, camera_num):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞: –¥–µ—Ç–µ–∫—Ü–∏—è, –æ—Ç–ø—Ä–∞–≤–∫–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç, —Ä–∏—Å–æ–≤–∞–Ω–∏–µ –±–æ–∫—Å–æ–≤"""
    frame_copy = frame.copy()

    cups = detect_persons(frame)

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –Ω–∞ —Å–µ—Ä–≤–µ—Ä
    send_coordinates(cups, camera_num)

    # –†–∏—Å—É–µ–º –±–æ–∫—Å—ã –≤–æ–∫—Ä—É–≥ –ª—é–¥–µ–π
    if cups:
        try:
            results = model(frame, conf=0.5, verbose=False, device=device)
            for result in results:
                for box in result.boxes:
                    if int(box.cls) == 0:
                        x1, y1, x2, y2 = map(int, box.xyxy[0])
                        conf = float(box.conf[0])
                        cv2.rectangle(frame_copy, (x1, y1), (x2, y2),
                                      (0, 0, 255), 2)
                        cv2.putText(frame_copy, f'Cup break: {conf:.2f}',
                                    (x1, y1 - 10),
                                    cv2.FONT_HERSHEY_SIMPLEX,
                                    1, (0, 0, 255), 2)
                    if int(box.cls) == 1:
                        x1, y1, x2, y2 = map(int, box.xyxy[0])
                        conf = float(box.conf[0])
                        cv2.rectangle(frame_copy, (x1, y1), (x2, y2),
                                      (0, 255, 0), 2)
                        cv2.putText(frame_copy, f'Cup ok: {conf:.2f}',
                                    (x1, y1 - 10),
                                    cv2.FONT_HERSHEY_SIMPLEX,
                                    1, (0, 255, 0), 2)
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç—Ä–∏—Å–æ–≤–∫–µ –±–æ–∫—Å–æ–≤: {e}")
    #os.makedirs('saved_frames', exist_ok=True)
    #filename = f'saved_frames/frame_cam1_{datetime.now().strftime("%Y%m%d_%H%M%S_%f")}.jpg'
    #cv2.imwrite(filename, frame)
    return frame_copy


def update_frames_camera1():
    global current_frame1, cap1
    last_time = time.time()

    while True:
        if cap1 is None or not cap1.isOpened():
            time.sleep(0.1)
            continue

        current_time = time.time()
        if current_time - last_time < FRAME_TIME:
            time.sleep(0.02)
            continue

        last_time = current_time

        ret, frame = cap1.read()
        #os.makedirs('saved_frames', exist_ok=True)
        #filename = f'saved_frames/frame_cam1_{datetime.now().strftime("%Y%m%d_%H%M%S_%f")}.jpg'
        #cv2.imwrite(filename, frame)
        if not ret:
            # –ú–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–∏—Ç—å, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            time.sleep(0.05)
            continue

        processed = process_frame(frame, 1)

        with frame_lock1:
            current_frame1 = processed


def update_frames_camera2():
    global current_frame2, cap2
    last_time = time.time()

    while True:
        if cap2 is None or not cap2.isOpened():
            time.sleep(0.1)
            continue

        current_time = time.time()
        if current_time - last_time < FRAME_TIME:
            time.sleep(0.02)
            continue

        last_time = current_time

        ret, frame = cap2.read()
        #os.makedirs('saved_frames', exist_ok=True)
        #filename = f'saved_frames/frame_cam2_{datetime.now().strftime("%Y%m%d_%H%M%S_%f")}.jpg'
        #cv2.imwrite(filename, frame)
        if not ret:
            time.sleep(0.05)
            continue

        processed = process_frame(frame, 2)

        with frame_lock2:
            current_frame2 = processed


@video_bp.route('/cameras', methods=['GET'])
def get_cameras():
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫–∞–º–µ—Ä.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ—Ç –∂–µ backend, —á—Ç–æ –∏ –æ—Å–Ω–æ–≤–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è.
    """
    max_tested = 10
    available_cameras = []

    for i in range(max_tested):
        test_cap = cv2.VideoCapture(i, CAMERA_BACKEND)
        if not test_cap.isOpened():
            test_cap.release()
            continue

        available_cameras.append({"id": i, "name": f"Camera {i}"})
        test_cap.release()

    return jsonify(available_cameras)


@video_bp.route('/select_camera/<int:camera_num>/<int:camera_id>', methods=['POST'])
def select_camera(camera_num, camera_id):
    """
    –í—ã–±–æ—Ä –∫–∞–º–µ—Ä—ã –¥–ª—è –ø–æ—Ç–æ–∫–∞ 1 –∏–ª–∏ 2.
    """
    init_camera(camera_id, camera_num)
    return jsonify({"camera_num": camera_num, "camera_id": camera_id})


@video_bp.route('/feed1')
def video_feed1():
    def generate():
        while True:
            with frame_lock1:
                if current_frame1 is None:
                    time.sleep(0.01)
                    continue
                ret, buffer = cv2.imencode('.jpg', current_frame1)
                if not ret:
                    continue
                frame_bytes = buffer.tobytes()
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')

    return Response(generate(),
                    mimetype='multipart/x-mixed-replace; boundary=frame')


@video_bp.route('/feed2')
def video_feed2():
    def generate():
        while True:
            with frame_lock2:
                if current_frame2 is None:
                    time.sleep(0.01)
                    continue
                ret, buffer = cv2.imencode('.jpg', current_frame2)
                if not ret:
                    continue
                frame_bytes = buffer.tobytes()
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')

    return Response(generate(),
                    mimetype='multipart/x-mixed-replace; boundary=frame')


# –°—Ç–∞—Ä—Ç–æ–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞–º–µ—Ä (–ø–æ–¥–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–π –∏–Ω–¥–µ–∫—Å—ã –ø–æ–¥ —Å–≤–æ—é —Å–∏—Å—Ç–µ–º—É)
init_camera('/dev/video1', 1) # !!!!!! –ø—Ä–æ–±–æ–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ
init_camera('/dev/video4', 2)

print(f"‚è±Ô∏è  –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ FPS: {MAX_FPS} –∫–∞–¥—Ä–æ–≤/—Å–µ–∫")
print(f"üì° –°–µ—Ä–≤–µ—Ä –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç: {SERVER_URL}")

threading.Thread(target=update_frames_camera1, daemon=True).start()
threading.Thread(target=update_frames_camera2, daemon=True).start()
